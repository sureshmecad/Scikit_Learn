{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue\" align=\"left\"> Random Forest </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/03/beginners-guide-random-forest-hyperparameter-tuning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\" align=\"left\"> 1. Theory </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1. Hyper Parameter](image/1.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. n_estimators (Number of trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How does increasing the number of trees lead to overfitting?**\n",
    "\n",
    "\n",
    "- Increasing the **number of trees** does **improve the model performance** to some extent. But after a certain point, if you keep increasing the number of trees, the model will start learning the data, instead of the pattern it is supposed to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **n_estimators : integer, optional (default=10)**. The number of trees in the forest.\n",
    "\n",
    "  .. versionchanged:: 0.20\n",
    "  \n",
    "     The default value of **``n_estimators``** will change from **10** in\n",
    "     version 0.20 to **100** in version 0.22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1. Hyper Parameter](image/2.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. max_features\n",
    "- Total number of features in datset is 100.\n",
    "\n",
    "\n",
    "- sqrt 100 =10. Randomly select 10 features for each node "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features{“auto”, “sqrt”, “log2”}, int or float, default=”auto”\n",
    "- The number of features to consider when looking for the best split:\n",
    "\n",
    "  - If int, then consider max_features features at each split.\n",
    "\n",
    "  - If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split.\n",
    "\n",
    "  - If “auto”, then max_features=sqrt(n_features).\n",
    "\n",
    "  - If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n",
    "\n",
    "  - If “log2”, then max_features=log2(n_features).\n",
    "\n",
    "  - If None, then max_features=n_features.\n",
    "\n",
    "**Note:** the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1. Hyper Parameter](image/3.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1. Hyper Parameter](image/4.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth : int, default=None\n",
    "- The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1. Hyper Parameter](image/5.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_split : int or float, default=2\n",
    "The minimum number of samples required to split an internal node:\n",
    "\n",
    "  - If int, then consider min_samples_split as the minimum number.\n",
    "\n",
    "  - If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_leaf : int or float, default=1\n",
    "The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
    "\n",
    "  - If int, then consider min_samples_leaf as the minimum number.\n",
    "\n",
    "  - If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criterion{“gini”, “entropy”}, default=”gini”\n",
    "- The function to measure the quality of a split.\n",
    "\n",
    "\n",
    "- Supported criteria are **“gini”** for the **Gini impurity** and **“entropy”** for the **information gain.** Note: this parameter is tree-specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue\" align=\"left\"> 2. CODE </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[50, 100,150,200,300],\n",
    "              'criterion':['gini','entropy'],\n",
    "              'max_depth':[5,10,50,100,200]}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=4)\n",
    "grid.fit(xx_train,yy_train)\n",
    "\n",
    "print(\"Tuned Model Parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "---------------------------------------------------------------------------------------\n",
    "Tuned Model Parameters: {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 100}\n",
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(criterion='gini', max_depth=200, n_estimators=100)\n",
    "rfc.fit(xx_train,yy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 50)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = RandomForestClassifier(n_jobs=-1)\n",
    "rf_p_dist={'max_depth':[3,5,10,None],\n",
    "              'n_estimators':[10,100,200,300,400,500],\n",
    "              'max_features':randint(1,3),\n",
    "               'criterion':['gini','entropy'],\n",
    "               'bootstrap':[True,False],\n",
    "               'min_samples_leaf':randint(1,4),\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypertuning_rscv(est, p_distr, nbr_iter,X,y):\n",
    "    rdmsearch = RandomizedSearchCV(est, param_distributions=p_distr,\n",
    "                                  n_jobs=-1, n_iter=nbr_iter, cv=9)\n",
    "    # CV = Cross-Validation ( here using Stratified KFold CV)\n",
    "    rdmsearch.fit(X,y)\n",
    "    ht_params = rdmsearch.best_params_\n",
    "    ht_score = rdmsearch.best_score_\n",
    "    return ht_params, ht_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_parameters, rf_ht_score = hypertuning_rscv(est, rf_p_dist, 40, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claasifier=RandomForestClassifier(n_jobs=-1, n_estimators=300,bootstrap= True,criterion='entropy',\n",
    "                                  max_depth=3,max_features=2,min_samples_leaf= 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['entropy','gini']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search CV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 5 fold cross validation, \n",
    "# search across 100 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator = reg_rf, param_distributions = random_grid,scoring='neg_mean_squared_error',\n",
    "                               n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)\n",
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_\n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    "{'n_estimators': 700,\n",
    " 'min_samples_split': 15,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue\" align=\"left\"> 3. Default Parameters </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **n_estimators : integer, optional (default=10)**. The number of trees in the forest.\n",
    "\n",
    "  .. versionchanged:: 0.20\n",
    "  \n",
    "     The default value of **``n_estimators``** will change from **10** in\n",
    "     version 0.20 to **100** in version 0.22.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------\n",
    "\n",
    "- Parameters currently in use:\n",
    "\n",
    "- {'bootstrap': True,\n",
    "\n",
    "  'criterion': 'mse',\n",
    "  \n",
    "  'max_depth': None,\n",
    "  \n",
    "  'max_features': 'auto',\n",
    "  \n",
    "  'max_leaf_nodes': None,\n",
    "  \n",
    "  'min_impurity_decrease': 0.0,\n",
    "  \n",
    "  'min_impurity_split': None,\n",
    "  \n",
    "  'min_samples_leaf': 1,\n",
    "  \n",
    "  'min_samples_split': 2,\n",
    "  \n",
    "  'min_weight_fraction_leaf': 0.0,\n",
    "  \n",
    "  'n_estimators': 10,\n",
    "  \n",
    "  'n_jobs': 1,\n",
    "  \n",
    "  'oob_score': False,\n",
    "  \n",
    "  'random_state': 42,\n",
    "  \n",
    "  'verbose': 0,\n",
    "  \n",
    "  'warm_start': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **main parameters** used by a **Random Forest Classifier** are:\n",
    "\n",
    "- **criterion** = the function used to evaluate the quality of a split.\n",
    "\n",
    "\n",
    "- **max_depth** = maximum number of levels allowed in each decision tree.\n",
    "\n",
    "\n",
    "- **max_features** = maximum number of features considered when splitting a node.\n",
    "\n",
    "\n",
    "- **min_samples_leaf** = minimum number of samples which can be stored in a tree leaf.\n",
    "\n",
    "\n",
    "- **min_samples_split** = minimum number of data points placed in a node before the node is split\n",
    "\n",
    "\n",
    "- **n_estimators** = number of trees in the ensamble.\n",
    "\n",
    "\n",
    "- **bootstrap** = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at parameters used by our current forest\n",
    "### from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "### Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
